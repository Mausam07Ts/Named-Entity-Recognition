{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC4RF_yyT2bZ",
        "outputId": "33ae3550-6579-4e4c-cb2b-8d76ab2efc8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "# Load a spacy model and chekc if it has ner\n",
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner=nlp.get_pipe(\"ner\")"
      ],
      "metadata": {
        "id": "IayS0h5i3BRU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training data\n",
        "TRAIN_DATA = [\n",
        "              (\"Walmart is a leading e-commerce company\", {\"entities\": [(0, 7, \"ORG\")]}),\n",
        "              (\"I reached Chennai yesterday.\", {\"entities\": [(19, 28, \"GPE\")]}),\n",
        "              (\"I recently ordered a book from Amazon\", {\"entities\": [(24,32, \"ORG\")]}),\n",
        "              (\"I was driving a BMW\", {\"entities\": [(16,19, \"PRODUCT\")]}),\n",
        "              (\"I ordered this from ShopClues\", {\"entities\": [(20,29, \"ORG\")]}),\n",
        "              (\"Fridge can be ordered in Amazon \", {\"entities\": [(0,6, \"PRODUCT\")]}),\n",
        "              (\"I bought a new Washer\", {\"entities\": [(16,22, \"PRODUCT\")]}),\n",
        "              (\"I bought a old table\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
        "              (\"I bought a fancy dress\", {\"entities\": [(18,23, \"PRODUCT\")]}),\n",
        "              (\"I rented a camera\", {\"entities\": [(12,18, \"PRODUCT\")]}),\n",
        "              (\"I rented a tent for our trip\", {\"entities\": [(12,16, \"PRODUCT\")]}),\n",
        "              (\"I rented a screwdriver from our neighbour\", {\"entities\": [(12,22, \"PRODUCT\")]}),\n",
        "              (\"I repaired my computer\", {\"entities\": [(15,23, \"PRODUCT\")]}),\n",
        "              (\"I got my clock fixed\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
        "              (\"I got my truck fixed\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
        "              (\"Flipkart started it's journey from zero\", {\"entities\": [(0,8, \"ORG\")]}),\n",
        "              (\"I recently ordered from Max\", {\"entities\": [(24,27, \"ORG\")]}),\n",
        "              (\"Flipkart is recognized as leader in market\",{\"entities\": [(0,8, \"ORG\")]}),\n",
        "              (\"I recently ordered from Swiggy\", {\"entities\": [(24,29, \"ORG\")]})\n",
        "              ]"
      ],
      "metadata": {
        "id": "fOvahN38Pq7E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding labels to the `ner`\n",
        "\n",
        "for _, annotations in TRAIN_DATA:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    ner.add_label(ent[2])"
      ],
      "metadata": {
        "id": "283WnCi0P-Ua"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable pipeline components you dont need to change\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
      ],
      "metadata": {
        "id": "lrjyvsy1QQGq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import requirements\n",
        "import random\n",
        "from spacy.util import minibatch, compounding\n",
        "from spacy.training.example import Example\n",
        "from pathlib import Path\n",
        "\n",
        "# TRAINING THE MODEL\n",
        "with nlp.disable_pipes(*unaffected_pipes):\n",
        "\n",
        "  # Training for 30 iterations\n",
        "  for iteration in range(30):\n",
        "\n",
        "    # shuufling examples  before every iteration\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        example = []\n",
        "        #Updating model with each iterating text\n",
        "        for i in range(len(texts)):\n",
        "          doc = nlp.make_doc(texts[i])\n",
        "          example.append(Example.from_dict(doc, annotations[i]))\n",
        "        # Update the model\n",
        "        nlp.update(example, drop=0.5, losses=losses)\n",
        "        print(\"Losses\", losses)\n",
        "    \n",
        "    \n",
        "          \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jWu6z533Nzu",
        "outputId": "d03235f2-e00a-4f5b-e77e-94bca7c63233"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I rented a screwdriver from our neighbour\" with entities \"[(12, 22, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I recently ordered a book from Amazon\" with entities \"[(24, 32, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I got my truck fixed\" with entities \"[(16, 21, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I bought a fancy dress\" with entities \"[(18, 23, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I repaired my computer\" with entities \"[(15, 23, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I rented a camera\" with entities \"[(12, 18, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I bought a old table\" with entities \"[(16, 21, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I reached Chennai yesterday.\" with entities \"[(19, 28, 'GPE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I rented a tent for our trip\" with entities \"[(12, 16, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I recently ordered from Swiggy\" with entities \"[(24, 29, 'ORG')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I got my clock fixed\" with entities \"[(16, 21, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I bought a new Washer\" with entities \"[(16, 22, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses {'ner': 0.28672915060582227}\n",
            "Losses {'ner': 0.8060134709813269}\n",
            "Losses {'ner': 8.039514235067657}\n",
            "Losses {'ner': 9.78121932773439}\n",
            "Losses {'ner': 11.864510696596978}\n",
            "Losses {'ner': 5.84704533109277}\n",
            "Losses {'ner': 5.855769439655972}\n",
            "Losses {'ner': 7.528628890321555}\n",
            "Losses {'ner': 7.532154572682257}\n",
            "Losses {'ner': 11.587715741026061}\n",
            "Losses {'ner': 0.40468386744049667}\n",
            "Losses {'ner': 0.4156463386986502}\n",
            "Losses {'ner': 1.3163882569069472}\n",
            "Losses {'ner': 6.99105037425443}\n",
            "Losses {'ner': 7.067504473637176}\n",
            "Losses {'ner': 1.2305979743166482}\n",
            "Losses {'ner': 2.853126776095351}\n",
            "Losses {'ner': 5.1202419944920035}\n",
            "Losses {'ner': 6.240172698635677}\n",
            "Losses {'ner': 9.239245030548503}\n",
            "Losses {'ner': 0.2699293374085858}\n",
            "Losses {'ner': 3.610151279643391}\n",
            "Losses {'ner': 4.9962906933262285}\n",
            "Losses {'ner': 4.996304539839534}\n",
            "Losses {'ner': 5.016959845112135}\n",
            "Losses {'ner': 1.3607585909383602}\n",
            "Losses {'ner': 1.3611101242366987}\n",
            "Losses {'ner': 2.911611742620812}\n",
            "Losses {'ner': 3.0311225936245223}\n",
            "Losses {'ner': 4.341252508018799}\n",
            "Losses {'ner': 1.7257180238006864}\n",
            "Losses {'ner': 1.7332669616491752}\n",
            "Losses {'ner': 3.2190908855790425}\n",
            "Losses {'ner': 3.2195239726138523}\n",
            "Losses {'ner': 6.465240861604086}\n",
            "Losses {'ner': 2.196062639159649}\n",
            "Losses {'ner': 2.225461895231544}\n",
            "Losses {'ner': 2.251699093109142}\n",
            "Losses {'ner': 2.251730646227342}\n",
            "Losses {'ner': 3.0193017825085837}\n",
            "Losses {'ner': 6.486237577938786e-05}\n",
            "Losses {'ner': 1.1063540600460988}\n",
            "Losses {'ner': 2.746407213494104}\n",
            "Losses {'ner': 2.7776432647888876}\n",
            "Losses {'ner': 5.326674171840364}\n",
            "Losses {'ner': 0.10237261496926593}\n",
            "Losses {'ner': 0.2909993962651571}\n",
            "Losses {'ner': 1.9131125241869094}\n",
            "Losses {'ner': 2.0159905343985733}\n",
            "Losses {'ner': 2.028129380367922}\n",
            "Losses {'ner': 2.058459130838856}\n",
            "Losses {'ner': 2.0585511587772354}\n",
            "Losses {'ner': 2.0585544909839197}\n",
            "Losses {'ner': 2.3905654469267494}\n",
            "Losses {'ner': 2.390568020906664}\n",
            "Losses {'ner': 3.715348102815154e-08}\n",
            "Losses {'ner': 8.325517051651681e-08}\n",
            "Losses {'ner': 0.0007921024317796452}\n",
            "Losses {'ner': 0.0009283484141362223}\n",
            "Losses {'ner': 0.6604986094615867}\n",
            "Losses {'ner': 0.4984909043538101}\n",
            "Losses {'ner': 0.498497387830828}\n",
            "Losses {'ner': 0.49849761052889496}\n",
            "Losses {'ner': 0.5332538013456013}\n",
            "Losses {'ner': 0.5332539163531522}\n",
            "Losses {'ner': 1.4621073000865116e-07}\n",
            "Losses {'ner': 9.741175217045156e-06}\n",
            "Losses {'ner': 0.7978083449602978}\n",
            "Losses {'ner': 0.7978198842129356}\n",
            "Losses {'ner': 0.7978198848613411}\n",
            "Losses {'ner': 0.00017807674062366753}\n",
            "Losses {'ner': 0.00019036683959370443}\n",
            "Losses {'ner': 0.001135385461207116}\n",
            "Losses {'ner': 0.0011367168812237447}\n",
            "Losses {'ner': 0.0011980616596112062}\n",
            "Losses {'ner': 0.518367375825859}\n",
            "Losses {'ner': 0.9098492405396752}\n",
            "Losses {'ner': 0.9098506636600038}\n",
            "Losses {'ner': 0.9098506676085066}\n",
            "Losses {'ner': 0.9098600865929615}\n",
            "Losses {'ner': 4.9860762928773475e-05}\n",
            "Losses {'ner': 0.14644770884538175}\n",
            "Losses {'ner': 1.9917717679073244}\n",
            "Losses {'ner': 1.9956970580508053}\n",
            "Losses {'ner': 1.9956987943152908}\n",
            "Losses {'ner': 0.03965647628570257}\n",
            "Losses {'ner': 0.03966203874685637}\n",
            "Losses {'ner': 0.039662040024764054}\n",
            "Losses {'ner': 0.09540750051961022}\n",
            "Losses {'ner': 0.09540781843196704}\n",
            "Losses {'ner': 3.07040322258302e-05}\n",
            "Losses {'ner': 6.0484484566030305e-05}\n",
            "Losses {'ner': 6.488618336108782e-05}\n",
            "Losses {'ner': 0.00019261199921562786}\n",
            "Losses {'ner': 0.00019261298988877465}\n",
            "Losses {'ner': 0.0002387596146305529}\n",
            "Losses {'ner': 0.0003992015844092466}\n",
            "Losses {'ner': 0.00046260310620752944}\n",
            "Losses {'ner': 0.0004660597120183694}\n",
            "Losses {'ner': 0.00048778546037084054}\n",
            "Losses {'ner': 1.2942874431822407e-06}\n",
            "Losses {'ner': 0.02503015864772997}\n",
            "Losses {'ner': 0.025031585736648643}\n",
            "Losses {'ner': 1.4755355074550602}\n",
            "Losses {'ner': 1.4908474623359578}\n",
            "Losses {'ner': 0.22048202599290956}\n",
            "Losses {'ner': 0.22048204325787432}\n",
            "Losses {'ner': 0.22048204413588324}\n",
            "Losses {'ner': 0.22048226113334168}\n",
            "Losses {'ner': 0.24672993109112076}\n",
            "Losses {'ner': 1.2195926200353103e-05}\n",
            "Losses {'ner': 0.00278314907660257}\n",
            "Losses {'ner': 0.0027831648624585892}\n",
            "Losses {'ner': 0.0030963420001578336}\n",
            "Losses {'ner': 0.0030968826612567733}\n",
            "Losses {'ner': 0.0006822423232655904}\n",
            "Losses {'ner': 0.017471309473562967}\n",
            "Losses {'ner': 0.0174713796828899}\n",
            "Losses {'ner': 0.01748657879318711}\n",
            "Losses {'ner': 0.017486579475131773}\n",
            "Losses {'ner': 3.187432356653206e-08}\n",
            "Losses {'ner': 1.0318716500757457}\n",
            "Losses {'ner': 1.0319054281229165}\n",
            "Losses {'ner': 1.0319065237155562}\n",
            "Losses {'ner': 1.0319065250730133}\n",
            "Losses {'ner': 8.742587673618937e-09}\n",
            "Losses {'ner': 0.00015046470572824613}\n",
            "Losses {'ner': 0.012516077323658498}\n",
            "Losses {'ner': 0.01267185634046871}\n",
            "Losses {'ner': 0.012675924301104225}\n",
            "Losses {'ner': 2.4768615575733055e-06}\n",
            "Losses {'ner': 2.0451320451435537e-05}\n",
            "Losses {'ner': 0.022224377767102895}\n",
            "Losses {'ner': 0.02222524452955193}\n",
            "Losses {'ner': 0.02289933680492611}\n",
            "Losses {'ner': 4.824926178565933e-09}\n",
            "Losses {'ner': 4.946667239243286e-06}\n",
            "Losses {'ner': 5.093201800649093e-06}\n",
            "Losses {'ner': 5.939242879642522e-06}\n",
            "Losses {'ner': 1.591259689666411e-05}\n",
            "Losses {'ner': 1.0586098124434668e-06}\n",
            "Losses {'ner': 0.6390934691124588}\n",
            "Losses {'ner': 0.6390949308167023}\n",
            "Losses {'ner': 0.6390949453563592}\n",
            "Losses {'ner': 0.6399032255797523}\n",
            "Losses {'ner': 2.32863802892092e-07}\n",
            "Losses {'ner': 2.8651866286543773e-06}\n",
            "Losses {'ner': 0.0002540186867908289}\n",
            "Losses {'ner': 0.0002540233414337006}\n",
            "Losses {'ner': 0.00025402386207883006}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "doc = nlp(\"I was driving a Alto\")\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_GRDSxnbWrT",
        "outputId": "c57bca51-22e6-4458-85f6-7326ebb0ca53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities [('Alto', 'PRODUCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1TjRCPBHvyrk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kEdnaKlx9-aI"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}